/*
 *  Copyright (c) 2007-2014,
 *  Commissariat a l'Energie Atomique (CEA)
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without modification,
 *  are permitted provided that the following conditions are met:
 *
 *   - Redistributions of source code must retain the above copyright notice, this
 *     list of conditions and the following disclaimer.
 *
 *   - Redistributions in binary form must reproduce the above copyright notice,
 *     this list of conditions and the following disclaimer in the documentation
 *     and/or other materials provided with the distribution.
 *
 *   - Neither the name of CEA nor the names of its contributors may be used to
 *     endorse or promote products derived from this software without specific prior
 *     written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 *  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED.
 *  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
 *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
 *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 *  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 *  OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 *  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
 *  EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * Authors: Daniel Gracia Perez (daniel.gracia-perez@cea.fr), Yves Lhuillier (yves.lhuillier@cea.fr)
 */
 
/**********************************************

        THUMB2 VFP INSTRUCTIONS

**********************************************/

/* VABS; Vector Absolute takes the absolute value of each element in a
 * vector, and places the results in a second vector. The
 * floating-point version only clears the sign bit.
 */

op vabs_f32s( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0000[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vabs_f32s.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vabs_f32s.disasm = {
  buffer << "vabs.f32\ts" << vd << ", s" << vm;
};

op vabs_f64d( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0000[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vabs_f64d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vabs_f64d.disasm = {
  buffer << "vabs.f64\td" << vd << ", d" << vm;
};

/* VADD; Vector Add adds corresponding elements in two vectors, and
 * places the results in the destination vector.
 */

op vadd_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b11[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vadd_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vadd_f32.disasm = {
  buffer << "vadd.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vadd_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b11[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vadd_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vadd_f64.disasm = {
  buffer << "vadd.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VCMP, VCMPE; Compares two floating-point registers, or one floating-point register and zero. It writes the result to
the FPSCR flags. These are normally transferred to the ARM flags by a subsequent VMRS instruction.
 */

op vcmp_f32d( 0b11101110[8]: 0b1[1]: vd1[1]: 0b11[2]: 0b0100[4]:> <: shl<1> vd0[4]: 0b1010[4]: e[1]: 0b1[1]: vm1[1]: 0b0[1]: shl<1> vm0[4] );
vcmp_f32d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcmp_f32d.disasm = {
  buffer << "vcmp" << (e?"e":"") << ".f32\ts" << vd << ", s" << vm;
};

op vcmp_f64d( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0100[4]:> <: vd0[4]: 0b1011[4]: e[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcmp_f64d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcmp_f64d.disasm = {
  buffer << "vcmp" << (e?"e":"") << ".f64\td" << vd << ", d" << vm;
};

op vcmp_f32i( 0b11101110[8]: 0b1[1]: vd1[1]: 0b11[2]: 0b0101[4]:> <: shl<1> vd0[4]: 0b1010[4]: e[1]: 0b100[3]: 0b0000[4] );
vcmp_f32i.var vd : {uint32_t} = {vd1|vd0};

vcmp_f32i.disasm = {
  buffer << "vcmp" << (e?"e":"") << ".f32\td" << vd << ", #0.0";
};

op vcmp_f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0101[4]:> <: vd0[4]: 0b1011[4]: e[1]: 0b100[3]: 0b0000[4] );
vcmp_f64i.var vd : {uint32_t} = {vd1|vd0};

vcmp_f64i.disasm = {
  buffer << "vcmp" << (e?"e":"") << ".f64\td" << vd << ", #0.0";
};

/* VCVT, VCVTR (Convert between floating-point and integer, Floating-point) */

op vcvt_f32u32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1000[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_f32u32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32u32.disasm = {
  buffer << "vcvt.f32.u32\ts" << vd << ", s" << vm;
};

op vcvt_f64u32( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1000[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_f64u32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64u32.disasm = {
  buffer << "vcvt.f64.u32\td" << vd << ", s" << vm;
};

op vcvt_f32s32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1000[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_f32s32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32s32.disasm = {
  buffer << "vcvt.f32.s32\ts" << vd << ", s" << vm;
};

op vcvt_f64s32( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1000[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_f64s32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64s32.disasm = {
  buffer << "vcvt.f64.s32\td" << vd << ", s" << vm;
};

op vcvt_u32f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1100[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_u32f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_u32f32.disasm = {
  buffer << "vcvt.u32.f32\ts" << vd << ", s" << vm;
};

op vcvt_u32f64( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1100[4]:> <: shl<1> vd1[4]: 0b1011[4]: 0b11[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcvt_u32f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_u32f64.disasm = {
  buffer << "vcvt.u32.f64\ts" << vd << ", d" << vm;
};

op vcvt_s32f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1101[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_s32f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_s32f32.disasm = {
  buffer << "vcvt.s32.f32\ts" << vd << ", s" << vm;
};

op vcvt_s32f64( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1101[4]:> <: shl<1> vd1[4]: 0b1011[4]: 0b11[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcvt_s32f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_s32f64.disasm = {
  buffer << "vcvt.s32.f64\ts" << vd << ", d" << vm;
};

op vcvtr_u32f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1100[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvtr_u32f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtr_u32f32.disasm = {
  buffer << "vcvtr.u32.f32\ts" << vd << ", s" << vm;
};

op vcvtr_u32f64( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1100[4]:> <: shl<1> vd1[4]: 0b1011[4]: 0b01[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcvtr_u32f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtr_u32f64.disasm = {
  buffer << "vcvtr.u32.f64\ts" << vd << ", d" << vm;
};

op vcvtr_s32f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1101[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvtr_s32f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtr_s32f32.disasm = {
  buffer << "vcvtr.s32.f32\ts" << vd << ", s" << vm;
};

op vcvtr_s32f64( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1101[4]:> <: shl<1> vd1[4]: 0b1011[4]: 0b01[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcvtr_s32f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtr_s32f64.disasm = {
  buffer << "vcvtr.s32.f64\ts" << vd << ", d" << vm;
};

/* VCVT (Convert between floating-point and fixed-point, Floating-point) */

op vcvt_f32s16i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1010[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f32s16i.var imm : {int32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32s16i.disasm = {
  buffer << "vcvt.f32.s16\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_f32s32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1010[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f32s32i.var imm : {int32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32s32i.disasm = {
  buffer << "vcvt.f32.s32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_f64s16i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1010[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f64s16i.var imm : {uint32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64s16i.disasm = {
  buffer << "vcvt.f64.s16\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_f64s32i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1010[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f64s32i.var imm : {uint32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64s32i.disasm = {
  buffer << "vcvt.f64.s32\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_f32u16i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1011[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f32u16i.var imm : {int32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32u16i.disasm = {
  buffer << "vcvt.f32.u16\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_f32u32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1011[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f32u32i.var imm : {int32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32u32i.disasm = {
  buffer << "vcvt.f32.u32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_f64u16i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1011[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f64u16i.var imm : {uint32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64u16i.disasm = {
  buffer << "vcvt.f64.u16\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_f64u32i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1011[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_f64u32i.var imm : {uint32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64u32i.disasm = {
  buffer << "vcvt.f64.u32\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_s16f32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1110[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_s16f32i.var imm : {int32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_s16f32i.disasm = {
  buffer << "vcvt.s16.f32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_s16f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1110[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_s16f64i.var imm : {uint32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_s16f64i.disasm = {
  buffer << "vcvt.s16.f64\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_s32f32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1110[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_s32f32i.var imm : {int32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_s32f32i.disasm = {
  buffer << "vcvt.s32.f32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_s32f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1110[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_s32f64i.var imm : {uint32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_s32f64i.disasm = {
  buffer << "vcvt.s32.f64\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_u16f32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1111[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_u16f32i.var imm : {int32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_u16f32i.disasm = {
  buffer << "vcvt.u16.f32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_u16f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1111[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_u16f64i.var imm : {uint32_t} = {16-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_u16f64i.disasm = {
  buffer << "vcvt.u16.f64\td" << vd << ", d" << vd << ", #" << imm;
};

op vcvt_u32f32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b1111[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_u32f32i.var imm : {int32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_u32f32i.disasm = {
  buffer << "vcvt.u32.f32\ts" << vd << ", s" << vd << ", #" << imm;
};

op vcvt_u32f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b1111[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: imm0[1]: 0b0[1]: shl<1> imm1[4] );
vcvt_u32f64i.var imm : {uint32_t} = {32-(imm1|imm0)}, vd : {uint32_t} = {vd1|vd0};

vcvt_u32f64i.disasm = {
  buffer << "vcvt.u32.f64\td" << vd << ", d" << vd << ", #" << imm;
};

/* VCVT (Convert between double-precision and single-precision) */

op vcvt_f64f32( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0111[4]:> <: vd0[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvt_f64f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f64f32.disasm = {
  buffer << "vcvt.f64.f32\td" << vd << ", s" << vm;
};

op vcvt_f32f64( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0111[4]:> <: shl<1> vd1[4]: 0b1011[4]: 0b11[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vcvt_f32f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvt_f32f64.disasm = {
  buffer << "vcvt.f32.f64\ts" << vd << ", d" << vm;
};

/* VCVTB, VCVTT (Convert between halfword precision (Bottom or Top) and single precision) */

op vcvtb_f16f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0011[4]:> <: shl<1> vd1[4]: 0b1010[4]: t[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvtb_f16f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtb_f16f32.disasm = {
  buffer << "vcvt" << (t?"t":"b") << ".f16.f32\ts" << vd << ", s" << vm;
};

op vcvtb_f32f16( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0010[4]:> <: shl<1> vd1[4]: 0b1010[4]: t[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vcvtb_f32f16.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vcvtb_f32f16.disasm = {
  buffer << "vcvt" << (t?"t":"b") << ".f32.f16\ts" << vd << ", s" << vm;
};

/* VDIV */

op vdiv_f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b00[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vdiv_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vdiv_f32.disasm = {
  buffer << "vdiv.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vdiv_f64( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b00[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vdiv_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vdiv_f64.disasm = {
  buffer << "vdiv.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VFMA, VFMS; Vector Fused Multiply Accumulate, Vector Fused Multiply Substract */

op vfma_f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b10[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vfma_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfma_f32.disasm = {
  buffer << "vfma.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vfma_f64( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b10[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vfma_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfma_f64.disasm = {
  buffer << "vfma.f64\td" << vd << ", d" << vn << ", d" << vm;
};

op vfms_f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b10[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vfms_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfms_f32.disasm = {
  buffer << "vfms.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vfms_f64( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b10[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vfms_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfms_f64.disasm = {
  buffer << "vfms.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VFNMA, VFNMS; Vector Fused Negate Multiply Accumulate, Vector Fused Negate Multiply Substract */

op vfnma_f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b01[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vfnma_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfnma_f32.disasm = {
  buffer << "vfnma.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vfnma_f64( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b01[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vfnma_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfnma_f64.disasm = {
  buffer << "vfnma.f64\td" << vd << ", d" << vn << ", d" << vm;
};

op vfnms_f32( 0b11101110[8]: 0b1[1]: vd0[1]: 0b01[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vfnms_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfnms_f32.disasm = {
  buffer << "vfnms.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vfnms_f64( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b01[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vfnms_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vfnms_f64.disasm = {
  buffer << "vfnms.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VLDM; Vector Load Multiple loads multiple extension registers from
 * consecutive memory locations using an address from an ARM core
 * register.
 */

op vldmdb_f32( 0b1110110[7]: 0b1[1]: 0b0[1]: vd0[1]: 0b11[2]: rn[4]:> <: shl<1> vd1[4]: 0b1010[4]: soff[8] );
vldmdb_f32.var vd : {uint32_t} = {vd1|vd0};

vldmdb_f32.disasm = {
  buffer << "vldmdb\t" << DisasmRegister(rn) << "!, ";
  int32_t send = ((int32_t)(vd + soff))-1;
  if (soff == 1) buffer << "{s" << vd << "}";
  else           buffer << "{s" << vd << "-s" << send << "}";
};

op vldmdb_f64( 0b1110110[7]: 0b1[1]: 0b0[1]: shl<4> vd1[1]: 0b11[2]: rn[4]:> <: vd0[4]: 0b1011[4]: ?[1]: doff[6]: 0b0[1] );
vldmdb_f64.var vd : {uint32_t} = {vd1|vd0};

vldmdb_f64.disasm = {
  buffer << "vldmdb\t" << DisasmRegister(rn) << "!, ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1)      buffer << "{d" << vd << "}";
  else if (dend < 32) buffer << "{d" << vd << "-d" << dend << "}";
  else                buffer << "{d" << vd << "-<overflow reg d" << dend << ">}";
};

op fldmdbx( 0b1110110[7]: 0b1[1]: 0b0[1]: shl<4> vd1[1]: 0b11[2]: rn[4]:> <: vd0[4]: 0b1011[4]: doff[7]: 0b1[1] );
fldmdbx.var vd : {uint32_t} = {vd1|vd0};

fldmdbx.disasm = {
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1) buffer << "fldmdbx\t" << DisasmRegister(rn) << "!, {d" << vd << "}";
  else           buffer << "fldmdbx\t" << DisasmRegister(rn) << "!, {d" << vd << "-d" << dend << "}";
};

op vldmia_f32( 0b1110110[7]: 0b0[1]: 0b1[1]: vd0[1]: w[1]: 0b1[1]: rn[4]:> <: shl<1> vd1[4]: 0b1010[4]: soff[8] );
vldmia_f32.var vd : {uint32_t} = {vd1|vd0};

vldmia_f32.disasm = {
  if ((rn == 13) and w)
    buffer << "vpop\t"; /* Syntaxic Sugar */
  else
    buffer << "vldmia\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t send = ((int32_t)(vd + soff))-1;
  if (soff == 1) buffer << "{s" << vd << "}";
  else           buffer << "{s" << vd << "-s" << send << "}";
};

op vldmia_f64( 0b1110110[7]: 0b0[1]: 0b1[1]: shl<4> vd1[1]: w[1]: 0b1[1]: rn[4]:> <: vd0[4]: 0b1011[4]: ?[1]: doff[6]: 0b0[1] );
vldmia_f64.var vd : {uint32_t} = {vd1|vd0};

vldmia_f64.disasm = {
  if ((rn == 13) and w)
    buffer << "vpop\t";
  else
    buffer << "vldmia\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1)      buffer << "{d" << vd << "}";
  else if (dend < 32) buffer << "{d" << vd << "-d" << dend << "}";
  else                buffer << "{d" << vd << "-<overflow reg d" << dend << ">}";
};

op fldmiax( 0b1110110[7]: 0b0[1]: 0b1[1]: shl<4> vd1[1]: w[1]: 0b1[1]: rn[4]:> <: vd0[4]: 0b1011[4]: doff[7]: 0b1[1] );
fldmiax.var vd : {uint32_t} = {vd1|vd0};

fldmiax.disasm = {
  buffer  << "fldmiax\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1) buffer << "{d" << vd << "}";
  else           buffer << "{d" << vd << "-d" << dend << "}";
};

/* VLDR; loads an a single extension register from memory, using an
 * address from an ARM core register, with optional offset.
 */

op vldr( 0b11101101[8]: u[1]: vd0[1]: 0b01[2]: rn[4]:> <: shl<1> vd1[4]: 0b1010[4]: shl<2> imm[8] );
vldr.var vd : {uint32_t} = {vd1|vd0};

vldr.disasm = {
  if (u and not imm) buffer << "vldr\ts" << vd << ", [" << DisasmRegister(rn) << "]";
  else                 buffer << "vldr\ts" << vd << ", [" << DisasmRegister(rn) << ", #" << (u?"":"-") << imm << "]";
};

op vldr_d( 0b11101101[8]: u[1]: shl<4> vd1[1]: 0b01[2]: rn[4]:> <: vd0[4]: 0b1011[4]: shl<2> imm[8] );
vldr_d.var vd : {uint32_t} = {vd1|vd0};

vldr_d.disasm = {
  if (u and not imm) buffer << "vldr\td" << vd << ", [" << DisasmRegister(rn) << "]";
  else                 buffer << "vldr\td" << vd << ", [" << DisasmRegister(rn) << ", #" << (u?"":"-") << imm << "]";
};

/* VMLA, VMLS; Multiplies corresponding elements in two vectors, and
 * accumulates the results into the elements of the destination
 * vector.
 */

op vmla_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b00[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vmla_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vmla_f32.disasm = {
  buffer << "vmla.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vmla_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b00[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vmla_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd0|vd1}, vn : {uint32_t} = {vn1|vn0};

vmla_f64.disasm = {
  buffer << "vmla.f64\td" << vd << ", d" << vn << ", d" << vm;
};

op vmls_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b00[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vmls_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vmls_f32.disasm = {
  buffer << "vmls.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vmls_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b00[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vmls_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd0|vd1}, vn : {uint32_t} = {vn1|vn0};

vmls_f64.disasm = {
  buffer << "vmls.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VMOV; Move immediate */

op vmov_f32i( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: n[1]: exp[3]:> <: shl<1> vd1[4]: 0b10100000[8]: man[4] );
vmov_f32i.var vd : {uint32_t} = {vd1|vd0}, fpimm : {float} = {(n?-1:1)*(float((0x10+man)<<(exp^4))/128)};

vmov_f32i.disasm = {
  buffer << "vmov.f32\ts" << vd << ", #" << fpimm;
};

op vmov_f64i( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: n[1]: exp[3]:> <: vd0[4]: 0b10110000[8]: man[4] );
vmov_f64i.var vd : {uint32_t} = {vd1|vd0}, fpimm : {float} = {(n?-1:1)*(float((0x10+man)<<(exp^4))/128)};

vmov_f64i.disasm = {
  buffer << "vmov.f64\td" << vd << ", #" << fpimm;
};

/* VMOV; move register */

op vmov_f32s( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0000[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vmov_f32s.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vmov_f32s.disasm = {
  buffer << "vmov.f32\ts" << vd << ", s" << vm;
};

op vmov_f64d( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0000[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vmov_f64d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vmov_f64d.disasm = {
  buffer << "vmov.f64\td" << vd << ", d" << vm;
};

/* VMOV; move arm core to scalar register */

op vmov32_dr( 0b11101110[8]: 0b00[2]: index[1]: 0b0[1]: vd0[4]:> <: rt[4]: 0b1011[4]: shl<4> vd1[1]: 0b001[3]: ?[4] );
vmov32_dr.var vd : {uint32_t} = {vd1|vd0};

vmov32_dr.disasm = {
  buffer << "vmov.32\td" << vd << "[" << index << "], " << DisasmRegister(rt);
};

// { ARCH::neon }:                                                         
op vmov16_dr( 0b11101110[8]: 0b00[2]: shl<1> index1[1]: 0b0[1]: vd0[4]:> <: rt[4]: 0b1011[4]: shl<4> vd1[1]: index0[1]: 0b11[2]: ?[4] );
vmov16_dr.var vd : {uint32_t} = {vd1|vd0}, index : {uint32_t} = {index1|index0};

vmov16_dr.disasm = {
  buffer << "vmov.16\td" << vd << "[" << index << "], " << DisasmRegister(rt);
};

// { ARCH::neon }:                                                         
op vmov8_dr( 0b11101110[8]: 0b01[2]: shl<2> index1[1]: 0b0[1]: vd0[4]:> <: rt[4]: 0b1011[4]: shl<4> vd1[1]: index0[2]: 0b1[1]: ?[4] );
vmov8_dr.var vd : {uint32_t} = {vd1|vd0}, index : {uint32_t} = {index1|index0};

vmov8_dr.disasm = {
  buffer << "vmov.8\td" << vd << "[" << index << "], " << DisasmRegister(rt);
};

/* VMOV; move scalar to arm core register */

op vmov_32rd( 0b11101110[8]: ?[1]: 0b0[1]: index[1]: 0b1[1]: vn0[4]:> <: rt[4]: 0b1011[4]: shl<4> vn1[1]: 0b001[3]: ?[4] );
vmov_32rd.var vn : {uint32_t} = {vn1|vn0};

vmov_32rd.disasm = {
  buffer << "vmov.32\t" << DisasmRegister(rt) << ", d" << vn << "[" << index << "]";
};

// { ARCH::neon }:                                                         
op vmov_s16rd( 0b11101110[8]: 0b00[2]: shl<1> index1[1]: 0b1[1]: vn0[4]:> <: rt[4]: 0b1011[4]: shl<4> vn1[1]: index0[1]: 0b11[2]: ?[4] );
vmov_s16rd.var vn : {uint32_t} = {vn1|vn0}, index : {uint32_t} = {index1|index0};

vmov_s16rd.disasm = {
  buffer << "vmov.s16\t" << DisasmRegister(rt) << ", d" << vn << "[" << index << "]";
};

// { ARCH::neon }:                                                         
op vmov_u16rd( 0b11101110[8]: 0b10[2]: shl<1> index1[1]: 0b1[1]: vn0[4]:> <: rt[4]: 0b1011[4]: shl<4> vn1[1]: index0[1]: 0b11[2]: ?[4] );
vmov_u16rd.var vn : {uint32_t} = {vn1|vn0}, index : {uint32_t} = {index1|index0};

vmov_u16rd.disasm = {
  buffer << "vmov.u16\t" << DisasmRegister(rt) << ", d" << vn << "[" << index << "]";
};

// { ARCH::neon }:                                                         
op vmov_s8rd( 0b11101110[8]: 0b01[2]: shl<2> index1[1]: 0b1[1]: vn0[4]:> <: rt[4]: 0b1011[4]: shl<4> vn1[1]: index0[2]: 0b1[1]: ?[4] );
vmov_s8rd.var vn : {uint32_t} = {vn1|vn0}, index : {uint32_t} = {index1|index0};

vmov_s8rd.disasm = {
  buffer << "vmov.s8\t" << DisasmRegister(rt) << ", d" << vn << "[" << index << "]";
};

// { ARCH::neon }:                                                         
op vmov_u8rd( 0b11101110[8]: 0b11[2]: shl<2> index1[1]: 0b1[1]: vn0[4]:> <: rt[4]: 0b1011[4]: shl<4> vn1[1]: index0[2]: 0b1[1]: ?[4] );
vmov_u8rd.var vn : {uint32_t} = {vn1|vn0}, index : {uint32_t} = {index1|index0};

vmov_u8rd.disasm = {
  buffer << "vmov.u8\t" << DisasmRegister(rt) << ", d" << vn << "[" << index << "]";
};

/* VMOV; Move between arm core register and single precision register */

op vmov_rs( 0b11101110[8]: 0b0001[4]: shl<1> vn1[4]:> <: rt[4]: 0b1010[4]: vn0[1]: 0b001[3]: 0b0000[4] );
vmov_rs.var vn : {uint32_t} = {vn1|vn0};

vmov_rs.disasm = {
  buffer << "vmov\t" << DisasmRegister(rt) << ", s" << vn;
};

op vmov_sr( 0b11101110[8]: 0b0000[4]: shl<1> vn1[4]:> <: rt[4]: 0b1010[4]: vn0[1]: 0b001[3]: 0b0000[4] );
vmov_sr.var vn : {uint32_t} = {vn1|vn0};

vmov_sr.disasm = {
  buffer << "vmov\ts" << vn << ", " << DisasmRegister(rt);
};

/* VMOV; Move between arm core register pair and single precision register pair */

op vmov_ssrr( 0b11101100[8]: 0b0100[4]: rt2[4]:> <: rt[4]: 0b1010[4]: 0b00[2]: vm0[1]: 0b1[1]: shl<1> vm1[4] );
vmov_ssrr.var vm : {uint32_t} = {vm1|vm0};

vmov_ssrr.disasm = {
  buffer << "vmov\ts" << vm << ", s" << (vm+1) << ", " << DisasmRegister(rt) << ", " << DisasmRegister(rt2);
};

op vmov_rrss( 0b11101100[8]: 0b0101[4]: rt2[4]:> <: rt[4]: 0b1010[4]: 0b00[2]: vm0[1]: 0b1[1]: shl<1> vm1[4] );
vmov_rrss.var vm : {uint32_t} = {vm1|vm0};

vmov_rrss.disasm = {
  buffer << "vmov\t" << DisasmRegister(rt) << ", " << DisasmRegister(rt2) << ", s" << vm << ", s" << (vm+1);
};

/* VMOV; Move between arm core register pair and double precision register */

op vmov_rrd( 0b11101100[8]: 0b0101[4]: rt2[4]:> <: rt[4]: 0b1011[4]: 0b00[2]: shl<4> vm1[1]: 0b1[1]: vm0[4] );
vmov_rrd.var vm : {uint32_t} = {vm0|vm1}

vmov_rrd.disasm = {
  buffer << "vmov\t" << DisasmRegister(rt) << ", " << DisasmRegister(rt2) << ", d" << vm;
};

op vmov_drr( 0b11101100[8]: 0b0100[4]: rt2[4]:> <: rt[4]: 0b1011[4]: 0b00[2]: shl<4> vm1[1]: 0b1[1]: vm0[4] );
vmov_drr.var vm : {uint32_t} = {vm0|vm1}

vmov_drr.disasm = {
  buffer << "vmov\td" << vm << ", " << DisasmRegister(rt) << ", " << DisasmRegister(rt2);
};

/* VMRS; Move to ARM core register from Advanced SIMD and Floating-point Extension System Register */

op vmrs( 0b1110[4]: 0b11101111[8]: spr[4]:> <: rt[4]: 0b1010[4]: 0b0001[4]: 0b0000[4] );

vmrs.disasm = {
  char const* spr_reg = 0;
  switch (spr) {
  default: buffer << "<undefined>"; return;
  case 0: spr_reg = "fpsid"; break;
  case 1: spr_reg = "fpscr"; break;
  case 6: spr_reg = "mvfr1"; break;
  case 7: spr_reg = "mvfrt"; break;
  case 8: spr_reg = "fpexc"; break;
  case 9: spr_reg = "fpinst\t@ Impl def"; break;
  case 10: spr_reg = "fpinst2\t@ Impl def"; break;
  }
  buffer << "vmrs\t";
  if ((rt == 15) and (spr == 1)) buffer << "APSR_nzcv";
  else                           buffer << DisasmRegister(rt);
  buffer << ", " << spr_reg;
};

op vmsr( 0b1110[4]: 0b11101110[8]: spr[4]:> <: rt[4]: 0b1010[4]: 0b0001[4]: 0b0000[4] );

vmsr.disasm = {
  char const* spr_reg = 0;
  switch (spr) {
  default: buffer << "<undefined>"; return;
  case 0: spr_reg = "fpsid"; break;
  case 1: spr_reg = "fpscr"; break;
  case 6: spr_reg = "mvfr1"; break;
  case 7: spr_reg = "mvfr0"; break;
  case 8: spr_reg = "fpexc"; break;
  case 9: spr_reg = "fpinst\t@ Impl def"; break;
  case 10: spr_reg = "fpinst2\t@ Impl def"; break;
  }
  buffer << "vmsr\t" << (spr_reg) << ", " << DisasmRegister(rt);
};

/* VMUL; Multiplies corresponding elements in two vectors, and places the results in the destination vector. */

op vmul_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b10[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vmul_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vmul_f32.disasm = {
  buffer << "vmul.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vmul_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b10[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vmul_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vmul_f64.disasm = {
  buffer << "vmul.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VNEG; Negates each element in a vector, and places the results in a second vector. */

op vneg_f32s( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0001[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b01[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vneg_f32s.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vneg_f32s.disasm = {
  buffer << "vneg.f32\ts" << vd << ", s" << vm;
};

op vneg_f64d( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0001[4]:> <: vd0[4]: 0b1011[4]: 0b01[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vneg_f64d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vneg_f64d.disasm = {
  buffer << "vneg.f64\td" << vd << ", d" << vm;
};

/* VNMLA; Multiplies together two floating-point register values, adds
 * the negation of the floating-point value in the destination
 * register to the negation of the product, and writes the result back
 * to the destination register.
 */

op vnmla_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b01[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vnmla_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmla_f32.disasm = {
  buffer << "vnmla.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vnmla_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b01[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vnmla_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmla_f64.disasm = {
  buffer << "vnmla.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VNMLS; multiplies together two floating-point register values, adds
 * the negation of the floating-point value in the destination
 * register to the product, and writes the result back to the
 * destination register.
 */

op vnmls_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b01[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b0[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vnmls_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmls_f32.disasm = {
  buffer << "vnmls.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vnmls_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b01[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b0[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vnmls_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmls_f64.disasm = {
  buffer << "vnmls.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VNMUL multiplies together two floating-point register values, and
 * writes the negation of the result to the destination register.
 */

op vnmul_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b10[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vnmul_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmul_f32.disasm = {
  buffer << "vnmul.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vnmul_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b10[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vnmul_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vnmul_f64.disasm = {
  buffer << "vnmul.f64\td" << vd << ", d" << vn << ", d" << vm;
};

/* VSQRT; Calculates the square root of a floating-point value. */

op vsqrt_f32s( 0b11101110[8]: 0b1[1]: vd0[1]: 0b11[2]: 0b0001[4]:> <: shl<1> vd1[4]: 0b1010[4]: 0b11[2]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vsqrt_f32s.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vsqrt_f32s.disasm = {
  buffer << "vsqrt.f32\ts" << vd << ", s" << vm;
};

op vsqrt_f64d( 0b11101110[8]: 0b1[1]: shl<4> vd1[1]: 0b11[2]: 0b0001[4]:> <: vd0[4]: 0b1011[4]: 0b11[2]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vsqrt_f64d.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0};

vsqrt_f64d.disasm = {
  buffer << "vsqrt.f64\td" << vd << ", d" << vm;
};

/* VSTM; Stores multiple extension registers to consecutive memory
 * locations using an address from an ARM core register.*/

op vstmdb_f32( 0b1110110[7]: 0b1[1]: 0b0[1]: vd0[1]: 0b10[2]: rn[4]:> <: shl<1> vd1[4]: 0b1010[4]: soff[8] );
vstmdb_f32.var vd : {uint32_t} = {vd1|vd0};

vstmdb_f32.disasm = {
  if (rn == 13) buffer << "vpush\t";
  else          buffer << "vstmdb\t" << DisasmRegister(rn) << "!, ";
  int32_t send = ((int32_t)(vd + soff))-1;
  if (soff == 1) buffer << "{s" << vd << "}";
  else           buffer << "{s" << vd << "-s" << send << "}";
};

op vstmdb_f64( 0b1110110[7]: 0b1[1]: 0b0[1]: shl<4> vd1[1]: 0b10[2]: rn[4]:> <: vd0[4]: 0b1011[4]: ?[1]: doff[6]: 0b0[1] );
vstmdb_f64.var vd : {uint32_t} = {vd1|vd0};

vstmdb_f64.disasm = {
  if (rn == 13) buffer << "vpush\t";
  else          buffer << "vstmdb\t" << DisasmRegister(rn) << "!, ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1)      buffer << "{d" << vd << "}";
  else if (dend < 32) buffer << "{d" << vd << "-d" << dend << "}";
  else                buffer << "{d" << vd << "-<overflow reg d" << dend << ">}";
};

op fstmdbx( 0b11101101[8]: 0b0[1]: shl<4> vd1[1]: 0b10[2]: r0[4]:> <: vd0[4]: 0b1011[4]: doff[7]: 0b1[1] );
fstmdbx.var vd : {uint32_t} = {vd1|vd0};

fstmdbx.disasm = {
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1) buffer << "fstmdbx\t" << DisasmRegister(r0) << "!, {d" << vd << "}";
  else           buffer << "fstmdbx\t" << DisasmRegister(r0) << "!, {d" << vd << "-d" << dend << "}";
};

op vstmia_f32( 0b1110110[7]: 0b0[1]: 0b1[1]: vd0[1]: w[1]: 0b0[1]: rn[4]:> <: shl<1> vd1[4]: 0b1010[4]: soff[8] );
vstmia_f32.var vd : {uint32_t} = {vd1|vd0};

vstmia_f32.disasm = {
  buffer << "vstmia\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t send = ((int32_t)(vd + soff))-1;
  if (soff == 1) buffer << "{s" << vd << "}";
  else           buffer << "{s" << vd << "-s" << send << "}";
};

op vstmia_f64( 0b1110110[7]: 0b0[1]: 0b1[1]: shl<4> vd1[1]: w[1]: 0b0[1]: rn[4]:> <: vd0[4]: 0b1011[4]: ?[1]: doff[6]: 0b0[1] );
vstmia_f64.var vd : {uint32_t} = {vd1|vd0};

vstmia_f64.disasm = {
  buffer << "vstmia\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1)      buffer << "{d" << vd << "}";
  else if (dend < 32) buffer << "{d" << vd << "-d" << dend << "}";
  else                buffer << "{d" << vd << "-<overflow reg d" << dend << ">}";
};

op fstmiax( 0b1110110[7]: 0b0[1]: 0b1[1]: shl<4> vd1[1]: w[1]: 0b0[1]: rn[4]:> <: vd0[4]: 0b1011[4]: doff[7]: 0b1[1] );
fstmiax.var vd : {uint32_t} = {vd1|vd0};

fstmiax.disasm = {
  buffer << "fstmiax\t" << DisasmRegister(rn) << (w?"!":"") << ", ";
  int32_t dend = ((int32_t)(vd + doff))-1;
  if (doff == 1) buffer << "{d" << vd << "}";
  else           buffer << "{d" << vd << "-d" << dend << "}";
};

/* VSTR This instruction stores a single extension register to memory,
 * using an address from an ARM core register, with an optional
 * offset.
 */

op vstr( 0b11101101[8]: u[1]: vn0[1]: 0b00[2]: rn[4]:> <: shl<1> vn1[4]: 0b1010[4]: shl<2> imm[8] );
vstr.var vn : {uint32_t} = {vn1|vn0};

vstr.disasm = {
  if (u and not imm) buffer << "vstr\ts" << vn << ", [" << DisasmRegister(rn) << "]";
  else               buffer << "vstr\ts" << vn << ", [" << DisasmRegister(rn) << ", #" << (u?"":"-") << imm << "]";
};

op vstr_d( 0b11101101[8]: u[1]: shl<4> vn1[1]: 0b00[2]: rn[4]:> <: vn0[4]: 0b1011[4]: shl<2> imm[8] );
vstr_d.var vn : {uint32_t} = {vn1|vn0};

vstr_d.disasm = {
  if (u and not imm) buffer << "vstr\td" << vn << ", [" << DisasmRegister(rn) << "]";
  else               buffer << "vstr\td" << vn << ", [" << DisasmRegister(rn) << ", #" << (u?"":"-") << imm << "]";
};

/* VSUB; Subtracts the elements of one vector from the corresponding
 * elements of another vector, and places the results in the
 * destination vector.
 */

op vsub_f32( 0b11101110[8]: 0b0[1]: vd0[1]: 0b11[2]: shl<1> vn1[4]:> <: shl<1> vd1[4]: 0b1010[4]: vn0[1]: 0b1[1]: vm0[1]: 0b0[1]: shl<1> vm1[4] );
vsub_f32.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vsub_f32.disasm = {
  buffer << "vsub.f32\ts" << vd << ", s" << vn << ", s" << vm;
};

op vsub_f64( 0b11101110[8]: 0b0[1]: shl<4> vd1[1]: 0b11[2]: vn0[4]:> <: vd0[4]: 0b1011[4]: shl<4> vn1[1]: 0b1[1]: shl<4> vm1[1]: 0b0[1]: vm0[4] );
vsub_f64.var vm : {uint32_t} = {vm1|vm0}, vd : {uint32_t} = {vd1|vd0}, vn : {uint32_t} = {vn1|vn0};

vsub_f64.disasm = {
  buffer << "vsub.f64\td" << vd << ", d" << vn << ", d" << vm;
};

